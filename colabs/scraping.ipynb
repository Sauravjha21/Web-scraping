{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0f0018",
   "metadata": {},
   "source": [
    "1. Go to the election comission of Bihar's website:- \n",
    "https://results.eci.gov.in/PcResultGenJune2024/partywiseresult-S04.htm \n",
    "\n",
    "2. Select districts from the dropdown:- \n",
    "https://results.eci.gov.in/PcResultGenJune2024/candidateswise-S049.htm \n",
    "\n",
    "3. Get the list of all the candidates, party name and the number of votes each candidate secured \n",
    "\n",
    "4. Store that in a table (csv file) that has following columns:- \n",
    "   a. Candidate name\n",
    "   b. Constituency \n",
    "   c. Party name \n",
    "   d. Number of votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da9c1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.select import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070174ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    # Set up Chrome options \n",
    "    \n",
    "    chrome_options = Options()\n",
    "    \n",
    "    # Set download directory to current working directory \n",
    "\n",
    "    download_dir = os.path.join(os.getcwd(), \"downloads\")\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    \n",
    "    prefs = {\n",
    "        \"download.default_directory\": download_dir,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": False\n",
    "    }\n",
    "    \n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    chrome_options.add_argument(\"--start-maximized\")  # Start with maximized window\n",
    "    \n",
    "    # Initialize the Chrome driver \n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options) \n",
    "\n",
    "    return driver, download_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9aa66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constituencies(driver, url):\n",
    "    # Open the main page\n",
    "    driver.get(url)\n",
    "    print(\"Main page loaded\")\n",
    "    \n",
    "    # Wait for the page to load\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Find the dropdown directly\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"ctl00_ContentPlaceHolder1_Result1_ddlState\"))\n",
    "        )\n",
    "        \n",
    "        # Get the constituency dropdown\n",
    "        dropdown = driver.find_element(By.ID, \"ctl00_ContentPlaceHolder1_Result1_ddlState\")\n",
    "        print(\"Found constituency dropdown\")\n",
    "        \n",
    "        # Get all options\n",
    "        select = Select(dropdown)\n",
    "        options = select.options\n",
    "        \n",
    "        # Extract constituencies (skip the first \"Select Constituency\" option)\n",
    "        constituencies = []\n",
    "        for option in options[1:]:  # Skip the first option as it's a placeholder\n",
    "            constituencies.append({\n",
    "                'text': option.text,\n",
    "                'value': option.get_attribute('value')\n",
    "            })\n",
    "        \n",
    "        print(f\"Found {len(constituencies)} constituencies\")\n",
    "        # Return only the first 5 constituencies for testing\n",
    "        return constituencies[:5]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting constituencies: {str(e)}\")\n",
    "        driver.save_screenshot(\"constituency_error.png\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_constituency_csv(driver, constituency, download_dir):\n",
    "    try:\n",
    "        # Find the constituency dropdown\n",
    "        dropdown = driver.find_element(By.ID, \"ctl00_ContentPlaceHolder1_Result1_ddlState\")\n",
    "        select = Select(dropdown)\n",
    "        \n",
    "        print(f\"Selecting constituency: {constituency['text']}\")\n",
    "        try:\n",
    "            select.select_by_visible_text(constituency['text'])\n",
    "        except:\n",
    "            try:\n",
    "                select.select_by_value(constituency['value'])\n",
    "            except Exception as e:\n",
    "                print(f\"Could not select constituency: {str(e)}\")\n",
    "                driver.save_screenshot(f\"select_error_{constituency['text'].replace(' ', '_')}.png\")\n",
    "                return None\n",
    "        \n",
    "        # Wait for the page to update\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Now we need to click on the constituency wise results link\n",
    "        try:\n",
    "            # Try to find the constituency link by href or by text\n",
    "            constituency_links = driver.find_elements(By.XPATH, \"//a[contains(@href, 'Constituencywise')]\")\n",
    "            \n",
    "            if constituency_links:\n",
    "                print(f\"Found constituency wise link: {constituency_links[0].get_attribute('href')}\")\n",
    "                constituency_links[0].click()\n",
    "                print(\"Clicked constituency wise link\")\n",
    "                time.sleep(3)  # Wait for page to load\n",
    "            else:\n",
    "                print(\"Could not find constituency wise link, taking screenshot...\")\n",
    "                driver.save_screenshot(f\"no_const_link_{constituency['text'].replace(' ', '_')}.png\")\n",
    "                \n",
    "                # Try to find any link that might contain constituency data\n",
    "                all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "                print(f\"Found {len(all_links)} links on the page\")\n",
    "                \n",
    "                for i, link in enumerate(all_links[:10]):  # Just check first 10 links\n",
    "                    href = link.get_attribute('href')\n",
    "                    text = link.text\n",
    "                    print(f\"Link {i}: href={href}, text={text}\")\n",
    "                \n",
    "                # Try another approach - look for specific elements\n",
    "                print(\"Looking for constituency elements by XPath...\")\n",
    "                try:\n",
    "                    constituency_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'card-header')]/following-sibling::div//a\")\n",
    "                    if constituency_elements:\n",
    "                        print(f\"Found {len(constituency_elements)} potential constituency elements\")\n",
    "                        constituency_elements[0].click()\n",
    "                        print(\"Clicked first potential constituency element\")\n",
    "                        time.sleep(3)\n",
    "                    else:\n",
    "                        print(\"No constituency elements found\")\n",
    "                        return None\n",
    "                except Exception as e:\n",
    "                    print(f\"Error finding constituency elements: {str(e)}\")\n",
    "                    return None\n",
    "            \n",
    "            # Now we should be on the table page\n",
    "            # Wait for the table to be present using the XPath you provided\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"/html/body/main/div/div[3]/div\"))\n",
    "                )\n",
    "                print(\"Found the table container\")\n",
    "                \n",
    "                # Get the table using the class names you provided\n",
    "                table = driver.find_element(By.CSS_SELECTOR, \"table.table.table-striped.table-bordered\")\n",
    "                print(\"Found the table\")\n",
    "                \n",
    "                # Extract headers from thead\n",
    "                headers = []\n",
    "                header_cells = table.find_elements(By.XPATH, \".//thead//th\")\n",
    "                for cell in header_cells:\n",
    "                    headers.append(cell.text.strip())\n",
    "                \n",
    "                print(f\"Found {len(headers)} headers: {headers}\")\n",
    "                \n",
    "                # Extract rows from tbody\n",
    "                rows = []\n",
    "                data_rows = table.find_elements(By.XPATH, \".//tbody//tr\")\n",
    "                print(f\"Found {len(data_rows)} rows\")\n",
    "                \n",
    "                for row in data_rows:\n",
    "                    row_data = []\n",
    "                    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                    for cell in cells:\n",
    "                        row_data.append(cell.text.strip())\n",
    "                    \n",
    "                    if row_data:  # Only add non-empty rows\n",
    "                        rows.append(row_data)\n",
    "                \n",
    "                print(f\"Processed {len(rows)} data rows\")\n",
    "                \n",
    "                # Create DataFrame\n",
    "                if headers and rows:\n",
    "                    # Make sure the number of columns matches\n",
    "                    max_cols = max(len(headers), max(len(row) for row in rows))\n",
    "                    \n",
    "                    # Extend headers if needed\n",
    "                    while len(headers) < max_cols:\n",
    "                        headers.append(f\"Column{len(headers)+1}\")\n",
    "                    \n",
    "                    # Extend rows if needed\n",
    "                    for row in rows:\n",
    "                        while len(row) < max_cols:\n",
    "                            row.append(\"\")\n",
    "                    \n",
    "                    df = pd.DataFrame(rows, columns=headers)\n",
    "                    \n",
    "                    # Save to CSV\n",
    "                    safe_constituency_name = constituency['text'].replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
    "                    csv_path = os.path.join(download_dir, f\"{safe_constituency_name}.csv\")\n",
    "                    \n",
    "                    # If the file already exists, remove it\n",
    "                    if os.path.exists(csv_path):\n",
    "                        os.remove(csv_path)\n",
    "                    \n",
    "                    df.to_csv(csv_path, index=False)\n",
    "                    print(f\"Extracted and saved table data to: {csv_path}\")\n",
    "                    return csv_path\n",
    "                else:\n",
    "                    print(\"No data found in table\")\n",
    "                    driver.save_screenshot(f\"no_data_{constituency['text'].replace(' ', '_')}.png\")\n",
    "                    return None\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting table for {constituency['text']}: {str(e)}\")\n",
    "                driver.save_screenshot(f\"table_error_{constituency['text'].replace(' ', '_')}.png\")\n",
    "                \n",
    "                # Try an alternative approach - look for any table\n",
    "                try:\n",
    "                    tables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "                    if tables:\n",
    "                        print(f\"Found {len(tables)} tables, trying first one\")\n",
    "                        table = tables[0]\n",
    "                        \n",
    "                        # Extract headers\n",
    "                        headers = []\n",
    "                        header_rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "                        if header_rows:\n",
    "                            header_cells = header_rows[0].find_elements(By.TAG_NAME, \"th\")\n",
    "                            if not header_cells:\n",
    "                                header_cells = header_rows[0].find_elements(By.TAG_NAME, \"td\")\n",
    "                            \n",
    "                            for cell in header_cells:\n",
    "                                headers.append(cell.text.strip())\n",
    "                        \n",
    "                        # Extract rows\n",
    "                        rows = []\n",
    "                        data_rows = table.find_elements(By.TAG_NAME, \"tr\")[1:]  # Skip header row\n",
    "                        for row in data_rows:\n",
    "                            row_data = []\n",
    "                            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                            for cell in cells:\n",
    "                                row_data.append(cell.text.strip())\n",
    "                            \n",
    "                            if row_data:\n",
    "                                rows.append(row_data)\n",
    "                        \n",
    "                        if headers and rows:\n",
    "                            df = pd.DataFrame(rows, columns=headers)\n",
    "                            safe_constituency_name = constituency['text'].replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
    "                            csv_path = os.path.join(download_dir, f\"{safe_constituency_name}.csv\")\n",
    "                            \n",
    "                            if os.path.exists(csv_path):\n",
    "                                os.remove(csv_path)\n",
    "                            \n",
    "                            df.to_csv(csv_path, index=False)\n",
    "                            print(f\"Extracted and saved table data using alternative method to: {csv_path}\")\n",
    "                            return csv_path\n",
    "                    else:\n",
    "                        print(\"No tables found on the page\")\n",
    "                except Exception as alt_e:\n",
    "                    print(f\"Alternative table extraction failed: {str(alt_e)}\")\n",
    "                \n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with navigation for {constituency['text']}: {str(e)}\")\n",
    "            driver.save_screenshot(f\"navigation_error_{constituency['text'].replace(' ', '_')}.png\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading CSV for {constituency['text']}: {str(e)}\")\n",
    "        driver.save_screenshot(f\"download_error_{constituency['text'].replace(' ', '_')}.png\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b78c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main page loaded\n",
      "Found constituency dropdown\n",
      "Found 40 constituencies\n",
      "Processing first 5 constituencies: ['Araria - 9', 'Arrah - 32', 'Aurangabad - 37', 'Banka - 27', 'Begusarai - 24']\n",
      "\n",
      "==================================================\n",
      "Processing: Araria - 9\n",
      "==================================================\n",
      "Selecting constituency: Araria - 9\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS049.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 10 rows\n",
      "Processed 10 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Araria_-_9.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Arrah - 32\n",
      "==================================================\n",
      "Selecting constituency: Arrah - 32\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0432.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 15 rows\n",
      "Processed 15 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Arrah_-_32.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Aurangabad - 37\n",
      "==================================================\n",
      "Selecting constituency: Aurangabad - 37\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0437.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 10 rows\n",
      "Processed 10 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Aurangabad_-_37.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Banka - 27\n",
      "==================================================\n",
      "Selecting constituency: Banka - 27\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0427.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 11 rows\n",
      "Processed 11 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Banka_-_27.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Begusarai - 24\n",
      "==================================================\n",
      "Selecting constituency: Begusarai - 24\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0424.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 11 rows\n",
      "Processed 11 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Begusarai_-_24.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Araria_-_9.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Arrah_-_32.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Aurangabad_-_37.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Banka_-_27.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Begusarai_-_24.csv\n",
      "Combined data saved to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/combined_constituency_data.csv\n",
      "Successfully combined data from 5 constituencies\n",
      "Combined data saved to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/combined_constituency_data.csv\n"
     ]
    }
   ],
   "source": [
    "def combine_csv_files(csv_files):\n",
    "    all_data = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        if file and os.path.exists(file):\n",
    "            try:\n",
    "                # Read CSV file\n",
    "                df = pd.read_csv(file, encoding='utf-8')\n",
    "                \n",
    "                # Add constituency name as a column (extracted from filename)\n",
    "                constituency_name = os.path.basename(file).replace('.csv', '').replace('_', ' ')\n",
    "                df['Constituency'] = constituency_name\n",
    "                \n",
    "                all_data.append(df)\n",
    "                print(f\"Added data from {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {str(e)}\")\n",
    "    \n",
    "    if all_data:\n",
    "        # Combine all DataFrames\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Save to a new CSV file\n",
    "        output_file = os.path.join(os.getcwd(), \"combined_constituency_data.csv\")\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"Combined data saved to: {output_file}\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(\"No data to combine\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bee26bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main page loaded\n",
      "Found constituency dropdown\n",
      "Found 40 constituencies\n",
      "Processing first 5 constituencies: ['Araria - 9', 'Arrah - 32', 'Aurangabad - 37', 'Banka - 27', 'Begusarai - 24']\n",
      "\n",
      "==================================================\n",
      "Processing: Araria - 9\n",
      "==================================================\n",
      "Selecting constituency: Araria - 9\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS049.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 10 rows\n",
      "Processed 10 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Araria_-_9.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Arrah - 32\n",
      "==================================================\n",
      "Selecting constituency: Arrah - 32\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0432.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 15 rows\n",
      "Processed 15 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Arrah_-_32.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Aurangabad - 37\n",
      "==================================================\n",
      "Selecting constituency: Aurangabad - 37\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0437.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 10 rows\n",
      "Processed 10 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Aurangabad_-_37.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Banka - 27\n",
      "==================================================\n",
      "Selecting constituency: Banka - 27\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0427.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 11 rows\n",
      "Processed 11 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Banka_-_27.csv\n",
      "\n",
      "==================================================\n",
      "Processing: Begusarai - 24\n",
      "==================================================\n",
      "Selecting constituency: Begusarai - 24\n",
      "Found constituency wise link: https://results.eci.gov.in/PcResultGenJune2024/ConstituencywiseS0424.htm\n",
      "Clicked constituency wise link\n",
      "Found the table container\n",
      "Found the table\n",
      "Found 7 headers: ['S.N.', 'Candidate', 'Party', 'EVM Votes', 'Postal Votes', 'Total Votes', '% of Votes']\n",
      "Found 11 rows\n",
      "Processed 11 data rows\n",
      "Extracted and saved table data to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Begusarai_-_24.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Araria_-_9.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Arrah_-_32.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Aurangabad_-_37.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Banka_-_27.csv\n",
      "Added data from /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/downloads/Begusarai_-_24.csv\n",
      "Combined data saved to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/combined_constituency_data.csv\n",
      "Successfully combined data from 5 constituencies\n",
      "Combined data saved to: /Users/sauravjha/Desktop/Hertie School/Semester 2/hertie-pdc-scraping/colabs/combined_constituency_data.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    url = \"https://results.eci.gov.in/PcResultGenJune2024/partywiseresult-S04.htm\"\n",
    "    \n",
    "    # Set up the driver\n",
    "    driver, download_dir = setup_driver()\n",
    "    \n",
    "    try:\n",
    "        # Get list of constituencies - limited to first 5\n",
    "        constituencies = get_constituencies(driver, url)\n",
    "        print(f\"Processing first 5 constituencies: {[c['text'] for c in constituencies]}\")\n",
    "        \n",
    "        # Download CSV for each constituency\n",
    "        csv_files = []\n",
    "        for constituency in constituencies:\n",
    "            print(f\"\\n{'='*50}\\nProcessing: {constituency['text']}\\n{'='*50}\")\n",
    "            \n",
    "            csv_file = download_constituency_csv(driver, constituency, download_dir)\n",
    "            if csv_file:\n",
    "                csv_files.append(csv_file)\n",
    "            \n",
    "            # Go back to the main page for the next constituency\n",
    "            driver.get(url)\n",
    "            time.sleep(3)\n",
    "        \n",
    "        # Combine all CSV files\n",
    "        if csv_files:\n",
    "            combined_file = combine_csv_files(csv_files)\n",
    "            if combined_file:\n",
    "                print(f\"Successfully combined data from {len(csv_files)} constituencies\")\n",
    "                print(f\"Combined data saved to: {combined_file}\")\n",
    "        else:\n",
    "            print(\"No CSV files were downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fdaf906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_constituency_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4ac0f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.N.</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Party</th>\n",
       "      <th>EVM Votes</th>\n",
       "      <th>Postal Votes</th>\n",
       "      <th>Total Votes</th>\n",
       "      <th>% of Votes</th>\n",
       "      <th>Constituency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PRADEEP KUMAR SINGH</td>\n",
       "      <td>Bharatiya Janata Party</td>\n",
       "      <td>599118</td>\n",
       "      <td>1028</td>\n",
       "      <td>600146</td>\n",
       "      <td>47.91</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SHAHNAWAZ</td>\n",
       "      <td>Rashtriya Janata Dal</td>\n",
       "      <td>578904</td>\n",
       "      <td>1148</td>\n",
       "      <td>580052</td>\n",
       "      <td>46.31</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SHATRUGHAN PRASAD SUMAN</td>\n",
       "      <td>Independent</td>\n",
       "      <td>13697</td>\n",
       "      <td>49</td>\n",
       "      <td>13746</td>\n",
       "      <td>1.10</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MD GHOUSUL AZAM</td>\n",
       "      <td>Bahujan Samaj Party</td>\n",
       "      <td>12672</td>\n",
       "      <td>18</td>\n",
       "      <td>12690</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MD. MOBINUL HAQUE</td>\n",
       "      <td>Independent</td>\n",
       "      <td>12005</td>\n",
       "      <td>3</td>\n",
       "      <td>12008</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>MD. ISMAIL</td>\n",
       "      <td>Bharatiya Momin Front</td>\n",
       "      <td>7353</td>\n",
       "      <td>1</td>\n",
       "      <td>7354</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>AKHILESH KUMAR</td>\n",
       "      <td>Independent</td>\n",
       "      <td>5086</td>\n",
       "      <td>34</td>\n",
       "      <td>5120</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>MUSHTAK ALAM</td>\n",
       "      <td>Independent</td>\n",
       "      <td>4897</td>\n",
       "      <td>2</td>\n",
       "      <td>4899</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ZAWED AKHTAR</td>\n",
       "      <td>The National Road Map Party of India</td>\n",
       "      <td>3037</td>\n",
       "      <td>4</td>\n",
       "      <td>3041</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NOTA</td>\n",
       "      <td>None of the Above</td>\n",
       "      <td>13438</td>\n",
       "      <td>66</td>\n",
       "      <td>13504</td>\n",
       "      <td>1.08</td>\n",
       "      <td>Araria - 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>SUDAMA PRASAD</td>\n",
       "      <td>Communist Party of India (Marxist-Leninist) (L...</td>\n",
       "      <td>526564</td>\n",
       "      <td>2818</td>\n",
       "      <td>529382</td>\n",
       "      <td>48.28</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>R. K. SINGH</td>\n",
       "      <td>Bharatiya Janata Party</td>\n",
       "      <td>464736</td>\n",
       "      <td>4838</td>\n",
       "      <td>469574</td>\n",
       "      <td>42.82</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>VIRENDRA KUMAR SINGH</td>\n",
       "      <td>Independent</td>\n",
       "      <td>23630</td>\n",
       "      <td>5</td>\n",
       "      <td>23635</td>\n",
       "      <td>2.16</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>SHIV DAS SINGH</td>\n",
       "      <td>Independent</td>\n",
       "      <td>13373</td>\n",
       "      <td>6</td>\n",
       "      <td>13379</td>\n",
       "      <td>1.22</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>LAL BADSAH SINGH</td>\n",
       "      <td>Bahujan Samaj Party</td>\n",
       "      <td>10631</td>\n",
       "      <td>195</td>\n",
       "      <td>10826</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>KRISHNA PASWAN</td>\n",
       "      <td>Bhartiya Kranti Vir Party</td>\n",
       "      <td>8709</td>\n",
       "      <td>40</td>\n",
       "      <td>8749</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>RANDHIR LAL</td>\n",
       "      <td>Independent</td>\n",
       "      <td>5765</td>\n",
       "      <td>1</td>\n",
       "      <td>5766</td>\n",
       "      <td>0.53</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>NAVNIT KUMAR</td>\n",
       "      <td>Independent</td>\n",
       "      <td>4764</td>\n",
       "      <td>9</td>\n",
       "      <td>4773</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>RAM SARE SINGH</td>\n",
       "      <td>Peoples Party of India (Democratic)</td>\n",
       "      <td>2531</td>\n",
       "      <td>10</td>\n",
       "      <td>2541</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>DHARMATMA SHARMA</td>\n",
       "      <td>Socialist Unity Centre Of India (COMMUNIST)</td>\n",
       "      <td>2449</td>\n",
       "      <td>18</td>\n",
       "      <td>2467</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>RAMJEE SINGH</td>\n",
       "      <td>Voters Party International</td>\n",
       "      <td>2435</td>\n",
       "      <td>5</td>\n",
       "      <td>2440</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>ASHOK TIWARY</td>\n",
       "      <td>Independent</td>\n",
       "      <td>2263</td>\n",
       "      <td>32</td>\n",
       "      <td>2295</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13</td>\n",
       "      <td>MANMOHAN SINGH</td>\n",
       "      <td>Rashtrawadi Janlok Party (Satya)</td>\n",
       "      <td>2055</td>\n",
       "      <td>42</td>\n",
       "      <td>2097</td>\n",
       "      <td>0.19</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14</td>\n",
       "      <td>SUMITRA DEVI</td>\n",
       "      <td>Jagrook Janta Party</td>\n",
       "      <td>1640</td>\n",
       "      <td>34</td>\n",
       "      <td>1674</td>\n",
       "      <td>0.15</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15</td>\n",
       "      <td>NOTA</td>\n",
       "      <td>None of the Above</td>\n",
       "      <td>16864</td>\n",
       "      <td>99</td>\n",
       "      <td>16963</td>\n",
       "      <td>1.55</td>\n",
       "      <td>Arrah - 32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S.N.                Candidate  \\\n",
       "0      1      PRADEEP KUMAR SINGH   \n",
       "1      2                SHAHNAWAZ   \n",
       "2      3  SHATRUGHAN PRASAD SUMAN   \n",
       "3      4          MD GHOUSUL AZAM   \n",
       "4      5        MD. MOBINUL HAQUE   \n",
       "5      6               MD. ISMAIL   \n",
       "6      7           AKHILESH KUMAR   \n",
       "7      8             MUSHTAK ALAM   \n",
       "8      9             ZAWED AKHTAR   \n",
       "9     10                     NOTA   \n",
       "10     1            SUDAMA PRASAD   \n",
       "11     2              R. K. SINGH   \n",
       "12     3     VIRENDRA KUMAR SINGH   \n",
       "13     4           SHIV DAS SINGH   \n",
       "14     5         LAL BADSAH SINGH   \n",
       "15     6           KRISHNA PASWAN   \n",
       "16     7              RANDHIR LAL   \n",
       "17     8             NAVNIT KUMAR   \n",
       "18     9           RAM SARE SINGH   \n",
       "19    10         DHARMATMA SHARMA   \n",
       "20    11             RAMJEE SINGH   \n",
       "21    12             ASHOK TIWARY   \n",
       "22    13           MANMOHAN SINGH   \n",
       "23    14             SUMITRA DEVI   \n",
       "24    15                     NOTA   \n",
       "\n",
       "                                                Party  EVM Votes  \\\n",
       "0                              Bharatiya Janata Party     599118   \n",
       "1                                Rashtriya Janata Dal     578904   \n",
       "2                                         Independent      13697   \n",
       "3                                 Bahujan Samaj Party      12672   \n",
       "4                                         Independent      12005   \n",
       "5                               Bharatiya Momin Front       7353   \n",
       "6                                         Independent       5086   \n",
       "7                                         Independent       4897   \n",
       "8                The National Road Map Party of India       3037   \n",
       "9                                   None of the Above      13438   \n",
       "10  Communist Party of India (Marxist-Leninist) (L...     526564   \n",
       "11                             Bharatiya Janata Party     464736   \n",
       "12                                        Independent      23630   \n",
       "13                                        Independent      13373   \n",
       "14                                Bahujan Samaj Party      10631   \n",
       "15                          Bhartiya Kranti Vir Party       8709   \n",
       "16                                        Independent       5765   \n",
       "17                                        Independent       4764   \n",
       "18                Peoples Party of India (Democratic)       2531   \n",
       "19        Socialist Unity Centre Of India (COMMUNIST)       2449   \n",
       "20                         Voters Party International       2435   \n",
       "21                                        Independent       2263   \n",
       "22                   Rashtrawadi Janlok Party (Satya)       2055   \n",
       "23                                Jagrook Janta Party       1640   \n",
       "24                                  None of the Above      16864   \n",
       "\n",
       "    Postal Votes  Total Votes  % of Votes Constituency  \n",
       "0           1028       600146       47.91   Araria - 9  \n",
       "1           1148       580052       46.31   Araria - 9  \n",
       "2             49        13746        1.10   Araria - 9  \n",
       "3             18        12690        1.01   Araria - 9  \n",
       "4              3        12008        0.96   Araria - 9  \n",
       "5              1         7354        0.59   Araria - 9  \n",
       "6             34         5120        0.41   Araria - 9  \n",
       "7              2         4899        0.39   Araria - 9  \n",
       "8              4         3041        0.24   Araria - 9  \n",
       "9             66        13504        1.08   Araria - 9  \n",
       "10          2818       529382       48.28   Arrah - 32  \n",
       "11          4838       469574       42.82   Arrah - 32  \n",
       "12             5        23635        2.16   Arrah - 32  \n",
       "13             6        13379        1.22   Arrah - 32  \n",
       "14           195        10826        0.99   Arrah - 32  \n",
       "15            40         8749        0.80   Arrah - 32  \n",
       "16             1         5766        0.53   Arrah - 32  \n",
       "17             9         4773        0.44   Arrah - 32  \n",
       "18            10         2541        0.23   Arrah - 32  \n",
       "19            18         2467        0.22   Arrah - 32  \n",
       "20             5         2440        0.22   Arrah - 32  \n",
       "21            32         2295        0.21   Arrah - 32  \n",
       "22            42         2097        0.19   Arrah - 32  \n",
       "23            34         1674        0.15   Arrah - 32  \n",
       "24            99        16963        1.55   Arrah - 32  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "569d2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c16ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Flags: ['flag-1', 'flag-10', 'flag-11', 'flag-12', 'flag-13', 'flag-14', 'flag-15', 'flag-16', 'flag-17', 'flag-18', 'flag-19', 'flag-2', 'flag-20', 'flag-21', 'flag-22', 'flag-23', 'flag-24', 'flag-25', 'flag-26', 'flag-27', 'flag-28', 'flag-29', 'flag-3', 'flag-30', 'flag-31', 'flag-32', 'flag-33', 'flag-34', 'flag-35', 'flag-36', 'flag-37', 'flag-38', 'flag-39', 'flag-4', 'flag-40', 'flag-5', 'flag-6', 'flag-7', 'flag-8', 'flag-9']\n",
      "Total Flags: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/bhmglhlx427341n1cdxtx73w0000gn/T/ipykernel_24859/608626320.py:55: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  text_elements = soup.find_all(text=True)\n",
      "/var/folders/00/bhmglhlx427341n1cdxtx73w0000gn/T/ipykernel_24859/608626320.py:148: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  comments = soup.find_all(text=lambda text: isinstance(text, Comment))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "\n",
    "def is_valid_flag(flag):\n",
    "    \"\"\"\n",
    "    Validate if a given string is a valid flag\n",
    "    \n",
    "    Args:\n",
    "        flag (str): Potential flag to validate\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if valid flag, False otherwise\n",
    "    \"\"\"\n",
    "    return (\n",
    "        isinstance(flag, str) and \n",
    "        flag.startswith('flag-') and \n",
    "        flag[5:].isdigit()\n",
    "    )\n",
    "\n",
    "def safe_finder(func):\n",
    "    \"\"\"\n",
    "    Decorator to handle exceptions in flag finding methods\n",
    "    \n",
    "    Args:\n",
    "        func (callable): Flag finding function to wrap\n",
    "    \n",
    "    Returns:\n",
    "        callable: Wrapped function with error handling\n",
    "    \"\"\"\n",
    "    def wrapper(soup):\n",
    "        try:\n",
    "            return func(soup)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {func.__name__}: {e}\")\n",
    "            return set()\n",
    "    return wrapper\n",
    "\n",
    "# Flag Finding Strategies\n",
    "@safe_finder\n",
    "def find_flags_in_elements_text(soup):\n",
    "    \"\"\"\n",
    "    Find flags in the text content of elements\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML\n",
    "    \n",
    "    Returns:\n",
    "        set: Flags found in element text\n",
    "    \"\"\"\n",
    "    flags = set()\n",
    "    \n",
    "    # Find all text elements\n",
    "    text_elements = soup.find_all(text=True)\n",
    "    \n",
    "    for text in text_elements:\n",
    "        # Split text into words\n",
    "        words = str(text).split()\n",
    "        \n",
    "        # Extract flag-like words\n",
    "        flags.update(word for word in words if word.startswith('flag-'))\n",
    "    \n",
    "    return flags\n",
    "\n",
    "@safe_finder\n",
    "def find_flags_in_attributes(soup):\n",
    "    \"\"\"\n",
    "    Find flags in various HTML attributes\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML\n",
    "    \n",
    "    Returns:\n",
    "        set: Flags found in attributes\n",
    "    \"\"\"\n",
    "    flags = set()\n",
    "    \n",
    "    # Find elements with attributes\n",
    "    elements = soup.find_all(attrs=lambda attrs: attrs)\n",
    "    \n",
    "    for elem in elements:\n",
    "        # Check all attributes\n",
    "        for attr_name, attr_value in elem.attrs.items():\n",
    "            # Handle list and string attributes\n",
    "            if isinstance(attr_value, list):\n",
    "                flags.update(\n",
    "                    val for val in attr_value \n",
    "                    if isinstance(val, str) and val.startswith('flag-')\n",
    "                )\n",
    "            elif isinstance(attr_value, str):\n",
    "                words = attr_value.split()\n",
    "                flags.update(word for word in words if word.startswith('flag-'))\n",
    "    \n",
    "    return flags\n",
    "\n",
    "@safe_finder\n",
    "def find_flags_in_special_attributes(soup):\n",
    "    \"\"\"\n",
    "    Find flags in special attributes like data-*, title, etc.\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML\n",
    "    \n",
    "    Returns:\n",
    "        set: Flags found in special attributes\n",
    "    \"\"\"\n",
    "    flags = set()\n",
    "    \n",
    "    # Special attribute types to check\n",
    "    special_attrs = [\n",
    "        lambda attrs: attrs and any(\n",
    "            key.startswith('data-') and \n",
    "            isinstance(attrs.get(key), str) and \n",
    "            'flag-' in attrs.get(key) \n",
    "            for key in attrs\n",
    "        ),\n",
    "        {'title': lambda x: x and 'flag-' in str(x)}\n",
    "    ]\n",
    "    \n",
    "    # Search for elements with special attributes\n",
    "    for attr_condition in special_attrs:\n",
    "        special_elements = soup.find_all(attrs=attr_condition)\n",
    "        \n",
    "        for elem in special_elements:\n",
    "            # Extract flags from attributes\n",
    "            for attr_name, attr_value in elem.attrs.items():\n",
    "                if isinstance(attr_value, str):\n",
    "                    words = attr_value.split()\n",
    "                    flags.update(word for word in words if word.startswith('flag-'))\n",
    "    \n",
    "    return flags\n",
    "\n",
    "@safe_finder\n",
    "def find_flags_in_comments(soup):\n",
    "    \"\"\"\n",
    "    Find flags in HTML comments\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML\n",
    "    \n",
    "    Returns:\n",
    "        set: Flags found in comments\n",
    "    \"\"\"\n",
    "    flags = set()\n",
    "    \n",
    "    # Find HTML comments\n",
    "    comments = soup.find_all(text=lambda text: isinstance(text, Comment))\n",
    "    \n",
    "    for comment in comments:\n",
    "        words = str(comment).split()\n",
    "        flags.update(word for word in words if word.startswith('flag-'))\n",
    "    \n",
    "    return flags\n",
    "\n",
    "@safe_finder\n",
    "def find_flags_in_hidden_elements(soup):\n",
    "    \"\"\"\n",
    "    Find flags in hidden or special CSS class elements\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML\n",
    "    \n",
    "    Returns:\n",
    "        set: Flags found in hidden elements\n",
    "    \"\"\"\n",
    "    flags = set()\n",
    "    \n",
    "    # Find hidden elements (various methods)\n",
    "    hidden_classes = [\n",
    "        'text-transparent',  # Transparent text\n",
    "        'hidden',            # Hidden class\n",
    "        'sr-only',           # Screen reader only\n",
    "    ]\n",
    "    \n",
    "    for cls in hidden_classes:\n",
    "        hidden_elements = soup.find_all(class_=cls)\n",
    "        \n",
    "        for elem in hidden_elements:\n",
    "            # Extract text and check for flags\n",
    "            if elem.string:\n",
    "                words = str(elem.string).split()\n",
    "                flags.update(word for word in words if word.startswith('flag-'))\n",
    "    \n",
    "    return flags\n",
    "\n",
    "@safe_finder\n",
    "def find_flags_in_ids(soup):\n",
    "    \"\"\"\n",
    "    Find flags in element IDs\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): Parsed HTML\n",
    "    \n",
    "    Returns:\n",
    "        set: Flags found in IDs\n",
    "    \"\"\"\n",
    "    flags = set()\n",
    "    \n",
    "    # Find elements with flag-like IDs\n",
    "    id_elements = soup.find_all(id=lambda x: x and 'flag-' in str(x))\n",
    "    \n",
    "    # Extract IDs that are flags\n",
    "    flags.update(\n",
    "        elem.get('id') for elem in id_elements \n",
    "        if elem.get('id') and elem.get('id').startswith('flag-')\n",
    "    )\n",
    "    \n",
    "    return flags\n",
    "\n",
    "def comprehensive_flag_extractor(url):\n",
    "    \"\"\"\n",
    "    Comprehensive flag extraction with multiple strategies\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL to scrape\n",
    "    \n",
    "    Returns:\n",
    "        list: Sorted list of unique, valid flags\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the page\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Combine all flag-finding strategies\n",
    "        flag_finders = [\n",
    "            find_flags_in_elements_text,\n",
    "            find_flags_in_attributes,\n",
    "            find_flags_in_special_attributes,\n",
    "            find_flags_in_comments,\n",
    "            find_flags_in_hidden_elements,\n",
    "            find_flags_in_ids\n",
    "        ]\n",
    "        \n",
    "        # Collect flags\n",
    "        all_flags = set()\n",
    "        for finder in flag_finders:\n",
    "            found_flags = finder(soup)\n",
    "            all_flags.update(found_flags)\n",
    "        \n",
    "        # Clean and validate flags\n",
    "        cleaned_flags = {flag for flag in all_flags if is_valid_flag(flag)}\n",
    "        \n",
    "        return sorted(cleaned_flags)\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Network error: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the flag extractor\n",
    "    \"\"\"\n",
    "    url = \"https://hertie-scraping-website.vercel.app/\"\n",
    "    \n",
    "    # Extract flags\n",
    "    found_flags = comprehensive_flag_extractor(url)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Found Flags:\", found_flags)\n",
    "    print(f\"Total Flags: {len(found_flags)}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3f88b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "23734840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:169: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:169: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/00/bhmglhlx427341n1cdxtx73w0000gn/T/ipykernel_24859/1420375089.py:49: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  flag_script = \"\"\"\n",
      "/var/folders/00/bhmglhlx427341n1cdxtx73w0000gn/T/ipykernel_24859/1420375089.py:117: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  hidden_flag_script = \"\"\"\n",
      "/var/folders/00/bhmglhlx427341n1cdxtx73w0000gn/T/ipykernel_24859/1420375089.py:169: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  styled_flag_script = \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flags Found on Level 2:\n",
      "flag-41\n",
      "flag-42\n",
      "flag-43\n",
      "flag-44\n",
      "flag-45\n",
      "flag-46\n",
      "flag-47\n",
      "flag-48\n",
      "flag-49\n",
      "flag-50\n",
      "flag-51\n",
      "flag-52\n",
      "flag-53\n",
      "flag-54\n",
      "\n",
      "Total Flags Found: 14\n"
     ]
    }
   ],
   "source": [
    "class Level2FlagHunter:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the Level 2 Flag Hunter\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL of the level 2 page\n",
    "        \"\"\"\n",
    "        # Setup Chrome options\n",
    "        chrome_options = Options()\n",
    "        # Uncomment the next line if you want to run in headless mode\n",
    "        # chrome_options.add_argument(\"--headless\")\n",
    "        \n",
    "        # Setup the WebDriver\n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=chrome_options\n",
    "        )\n",
    "        \n",
    "        self.url = url\n",
    "        # Existing flags to exclude\n",
    "        self.existing_flags = set(f'flag-{i}' for i in range(1, 41))\n",
    "    \n",
    "    def load_page(self):\n",
    "        \"\"\"\n",
    "        Load the target page and wait for it to stabilize\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.driver.get(self.url)\n",
    "            # Wait for page to load\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, 'body'))\n",
    "            )\n",
    "            time.sleep(2)  # Additional stabilization time\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading page: {e}\")\n",
    "    \n",
    "    def extract_flags_comprehensively(self):\n",
    "        \"\"\"\n",
    "        Comprehensive method to extract flags from the level 2 page\n",
    "        \n",
    "        Returns:\n",
    "            set: All flags found on the page\n",
    "        \"\"\"\n",
    "        flags = set()\n",
    "        \n",
    "        try:\n",
    "            # Comprehensive JavaScript to find flags\n",
    "            flag_script = \"\"\"\n",
    "            function extractFlags() {\n",
    "                const flags = new Set();\n",
    "                \n",
    "                // Function to check if a string is a flag\n",
    "                function isFlag(str) {\n",
    "                    return /flag-\\d+/.test(str);\n",
    "                }\n",
    "                \n",
    "                // Search through entire document\n",
    "                const walker = document.createTreeWalker(\n",
    "                    document.body,\n",
    "                    NodeFilter.SHOW_TEXT | NodeFilter.SHOW_ELEMENT,\n",
    "                    null,\n",
    "                    false\n",
    "                );\n",
    "                \n",
    "                let node;\n",
    "                while (node = walker.nextNode()) {\n",
    "                    // Check text content of text nodes\n",
    "                    if (node.nodeType === Node.TEXT_NODE && node.textContent) {\n",
    "                        const matches = node.textContent.match(/flag-\\d+/g);\n",
    "                        if (matches) {\n",
    "                            matches.forEach(match => flags.add(match));\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    // Check attributes of element nodes\n",
    "                    if (node.nodeType === Node.ELEMENT_NODE) {\n",
    "                        // Check all attributes\n",
    "                        for (let attr of node.attributes) {\n",
    "                            if (isFlag(attr.value)) {\n",
    "                                flags.add(attr.value);\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        // Check for flag-like class names\n",
    "                        if (node.className && isFlag(node.className)) {\n",
    "                            flags.add(node.className);\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                return Array.from(flags);\n",
    "            }\n",
    "            \n",
    "            return extractFlags();\n",
    "            \"\"\"\n",
    "            \n",
    "            # Execute the script\n",
    "            flags = set(self.driver.execute_script(flag_script))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting flags: {e}\")\n",
    "        \n",
    "        return flags\n",
    "    \n",
    "    def find_hidden_flags(self):\n",
    "        \"\"\"\n",
    "        Find flags in hidden or hard-to-detect elements\n",
    "        \n",
    "        Returns:\n",
    "            set: Hidden flags found\n",
    "        \"\"\"\n",
    "        hidden_flags = set()\n",
    "        \n",
    "        try:\n",
    "            # JavaScript to reveal and find hidden flags\n",
    "            hidden_flag_script = \"\"\"\n",
    "            function findHiddenFlags() {\n",
    "                const flags = new Set();\n",
    "                \n",
    "                // Find potentially hidden elements\n",
    "                const hiddenElements = document.querySelectorAll(\n",
    "                    '[style*=\"display:none\"],' +\n",
    "                    '[style*=\"visibility:hidden\"],' +\n",
    "                    '[style*=\"opacity:0\"],' +\n",
    "                    '.hidden,' +\n",
    "                    '.invisible,' +\n",
    "                    '.text-transparent'\n",
    "                );\n",
    "                \n",
    "                // Reveal and search hidden elements\n",
    "                hiddenElements.forEach(el => {\n",
    "                    // Make element visible\n",
    "                    el.style.display = 'block';\n",
    "                    el.style.visibility = 'visible';\n",
    "                    el.style.opacity = '1';\n",
    "                    \n",
    "                    // Search for flags\n",
    "                    const matches = el.textContent.match(/flag-\\d+/g);\n",
    "                    if (matches) {\n",
    "                        matches.forEach(match => flags.add(match));\n",
    "                    }\n",
    "                });\n",
    "                \n",
    "                return Array.from(flags);\n",
    "            }\n",
    "            \n",
    "            return findHiddenFlags();\n",
    "            \"\"\"\n",
    "            \n",
    "            hidden_flags = set(self.driver.execute_script(hidden_flag_script))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error finding hidden flags: {e}\")\n",
    "        \n",
    "        return hidden_flags\n",
    "    \n",
    "    def search_rotated_and_styled_elements(self):\n",
    "        \"\"\"\n",
    "        Search for flags in rotated, skewed, or specially styled elements\n",
    "        \n",
    "        Returns:\n",
    "            set: Flags found in specially styled elements\n",
    "        \"\"\"\n",
    "        styled_flags = set()\n",
    "        \n",
    "        try:\n",
    "            # JavaScript to search styled elements\n",
    "            styled_flag_script = \"\"\"\n",
    "            function findStyledFlags() {\n",
    "                const flags = new Set();\n",
    "                \n",
    "                // Find elements with specific styling that might hide flags\n",
    "                const styledElements = document.querySelectorAll(\n",
    "                    '.rotate-90, .rotate-45, .rotate-180, ' +\n",
    "                    '.skew-y-12, .text-xs, .opacity-25, .text-4xl'\n",
    "                );\n",
    "                \n",
    "                styledElements.forEach(el => {\n",
    "                    // Search for flags in text content\n",
    "                    const matches = el.textContent.match(/flag-\\d+/g);\n",
    "                    if (matches) {\n",
    "                        matches.forEach(match => flags.add(match));\n",
    "                    }\n",
    "                    \n",
    "                    // Check child elements\n",
    "                    const childMatches = el.innerHTML.match(/flag-\\d+/g);\n",
    "                    if (childMatches) {\n",
    "                        childMatches.forEach(match => flags.add(match));\n",
    "                    }\n",
    "                });\n",
    "                \n",
    "                return Array.from(flags);\n",
    "            }\n",
    "            \n",
    "            return findStyledFlags();\n",
    "            \"\"\"\n",
    "            \n",
    "            styled_flags = set(self.driver.execute_script(styled_flag_script))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error finding styled flags: {e}\")\n",
    "        \n",
    "        return styled_flags\n",
    "    \n",
    "    def find_level2_flags(self):\n",
    "        \"\"\"\n",
    "        Comprehensive method to find all flags on level 2 page\n",
    "        \n",
    "        Returns:\n",
    "            set: All unique flags found\n",
    "        \"\"\"\n",
    "        # Combine flag-finding methods\n",
    "        flag_methods = [\n",
    "            self.extract_flags_comprehensively,\n",
    "            self.find_hidden_flags,\n",
    "            self.search_rotated_and_styled_elements\n",
    "        ]\n",
    "        \n",
    "        # Collect flags\n",
    "        all_flags = set()\n",
    "        for method in flag_methods:\n",
    "            try:\n",
    "                method_flags = method()\n",
    "                all_flags.update(method_flags)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {method.__name__}: {e}\")\n",
    "        \n",
    "        # Remove existing flags and validate\n",
    "        unique_flags = {\n",
    "            flag for flag in all_flags \n",
    "            if flag.startswith('flag-') and \n",
    "               flag[5:].isdigit() and \n",
    "               flag not in self.existing_flags\n",
    "        }\n",
    "        \n",
    "        return unique_flags\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"\n",
    "        Close the browser and clean up resources\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Level 2 flag hunter\n",
    "    \"\"\"\n",
    "    url = \"https://hertie-scraping-website.vercel.app/level2\"\n",
    "    \n",
    "    # Create FlagHunter instance\n",
    "    flag_hunter = Level2FlagHunter(url)\n",
    "    \n",
    "    try:\n",
    "        # Load the page\n",
    "        flag_hunter.load_page()\n",
    "        \n",
    "        # Find flags\n",
    "        found_flags = flag_hunter.find_level2_flags()\n",
    "        \n",
    "        # Print results\n",
    "        print(\"Flags Found on Level 2:\")\n",
    "        for flag in sorted(found_flags):\n",
    "            print(flag)\n",
    "        print(f\"\\nTotal Flags Found: {len(found_flags)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Always ensure browser is closed\n",
    "        flag_hunter.cleanup()\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e46dea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flags Found on Level 3:\n",
      "flag-55\n",
      "flag-56\n",
      "flag-57\n",
      "flag-58\n",
      "flag-59\n",
      "flag-60\n",
      "\n",
      "Total Flags Found: 6\n"
     ]
    }
   ],
   "source": [
    "class Level3FlagHunter:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the Level 3 Flag Hunter\n",
    "        \"\"\"\n",
    "        # Setup Chrome options\n",
    "        chrome_options = Options()\n",
    "        \n",
    "        # Add options to prevent detection and improve stability\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-extensions\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--log-level=3\")  # Minimize logging\n",
    "        \n",
    "        # Setup the WebDriver with more robust service\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        service.creationflags = 0x08000000  # Prevents console window from appearing on Windows\n",
    "        \n",
    "        # Create WebDriver\n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=service,\n",
    "            options=chrome_options\n",
    "        )\n",
    "        \n",
    "        # Set longer timeouts\n",
    "        self.driver.set_page_load_timeout(30)\n",
    "        self.driver.implicitly_wait(10)\n",
    "        \n",
    "        self.url = url\n",
    "        # Existing flags to exclude (up to level 2)\n",
    "        self.existing_flags = set(f'flag-{i}' for i in range(1, 55))\n",
    "    \n",
    "    def load_page(self):\n",
    "        \"\"\"\n",
    "        Load the target page and wait for it to stabilize\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Navigate to the page\n",
    "            self.driver.get(self.url)\n",
    "            \n",
    "            # Wait for page to load completely\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, 'body'))\n",
    "            )\n",
    "            \n",
    "            # Additional wait for potential dynamic content\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # Print page source for debugging if needed\n",
    "            # print(self.driver.page_source)\n",
    "        \n",
    "        except TimeoutException:\n",
    "            print(\"Timeout while loading the page\")\n",
    "            # Attempt to get partial page source\n",
    "            print(\"Partial page source:\", self.driver.page_source[:1000])\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading page: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def extract_and_click_flags(self):\n",
    "        \"\"\"\n",
    "        Extract flags and click on specific buttons to reveal more\n",
    "        \n",
    "        Returns:\n",
    "            set: Unique flags found\n",
    "        \"\"\"\n",
    "        flags = set()\n",
    "        \n",
    "        try:\n",
    "            # Find all buttons with more robust method\n",
    "            try:\n",
    "                buttons = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.TAG_NAME, 'button'))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                print(\"No buttons found on the page\")\n",
    "                buttons = []\n",
    "            \n",
    "            # Buttons to click (with IDs 55, 57, 59)\n",
    "            click_ids = ['flag-55', 'flag-57', 'flag-59']\n",
    "            \n",
    "            # First, extract initial flags\n",
    "            for button in buttons:\n",
    "                try:\n",
    "                    # Try to get button text\n",
    "                    button_text = button.text.strip()\n",
    "                    \n",
    "                    # Check if text starts with flag-\n",
    "                    if button_text.startswith('flag-'):\n",
    "                        flags.add(button_text)\n",
    "                    \n",
    "                    # Check button ID\n",
    "                    button_id = button.get_attribute('id')\n",
    "                    if button_id and button_id.startswith('flag-'):\n",
    "                        flags.add(button_id)\n",
    "                \n",
    "                except Exception as button_error:\n",
    "                    print(f\"Error processing button: {button_error}\")\n",
    "            \n",
    "            # Click specific buttons to reveal more flags\n",
    "            for click_id in click_ids:\n",
    "                try:\n",
    "                    # Find and click the button with explicit wait\n",
    "                    click_button = WebDriverWait(self.driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.ID, click_id))\n",
    "                    )\n",
    "                    \n",
    "                    # Scroll to the button to ensure it's in view\n",
    "                    self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", click_button)\n",
    "                    \n",
    "                    # Wait a moment\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Click the button\n",
    "                    click_button.click()\n",
    "                    \n",
    "                    # Wait for potential dynamic content\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    # Re-find buttons after click\n",
    "                    new_buttons = self.driver.find_elements(By.TAG_NAME, 'button')\n",
    "                    \n",
    "                    # Extract new flags\n",
    "                    for button in new_buttons:\n",
    "                        try:\n",
    "                            # Try to get button text\n",
    "                            button_text = button.text.strip()\n",
    "                            \n",
    "                            # Check if text starts with flag-\n",
    "                            if button_text.startswith('flag-'):\n",
    "                                flags.add(button_text)\n",
    "                            \n",
    "                            # Check button ID\n",
    "                            button_id = button.get_attribute('id')\n",
    "                            if button_id and button_id.startswith('flag-'):\n",
    "                                flags.add(button_id)\n",
    "                        \n",
    "                        except Exception as new_button_error:\n",
    "                            print(f\"Error processing new button: {new_button_error}\")\n",
    "                \n",
    "                except (NoSuchElementException, TimeoutException) as click_error:\n",
    "                    print(f\"Error clicking button {click_id}: {click_error}\")\n",
    "                    # Additional debugging\n",
    "                    print(\"Available button IDs:\")\n",
    "                    for btn in self.driver.find_elements(By.TAG_NAME, 'button'):\n",
    "                        print(btn.get_attribute('id'))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error extracting and clicking flags: {e}\")\n",
    "        \n",
    "        return flags\n",
    "    \n",
    "    def find_level3_flags(self):\n",
    "        \"\"\"\n",
    "        Find all unique flags on level 3 page\n",
    "        \n",
    "        Returns:\n",
    "            set: All unique flags found\n",
    "        \"\"\"\n",
    "        # Extract flags by clicking buttons\n",
    "        found_flags = self.extract_and_click_flags()\n",
    "        \n",
    "        # Remove existing flags and validate\n",
    "        unique_flags = {\n",
    "            flag for flag in found_flags \n",
    "            if flag.startswith('flag-') and \n",
    "               flag[5:].isdigit() and \n",
    "               flag not in self.existing_flags\n",
    "        }\n",
    "        \n",
    "        return unique_flags\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"\n",
    "        Close the browser and clean up resources\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Level 3 flag hunter\n",
    "    \"\"\"\n",
    "    url = \"https://hertie-scraping-website.vercel.app/level3\"\n",
    "    \n",
    "    # Create FlagHunter instance\n",
    "    flag_hunter = Level3FlagHunter(url)\n",
    "    \n",
    "    try:\n",
    "        # Load the page\n",
    "        flag_hunter.load_page()\n",
    "        \n",
    "        # Find flags\n",
    "        found_flags = flag_hunter.find_level3_flags()\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nFlags Found on Level 3:\")\n",
    "        for flag in sorted(found_flags):\n",
    "            print(flag)\n",
    "        print(f\"\\nTotal Flags Found: {len(found_flags)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Always ensure browser is closed\n",
    "        flag_hunter.cleanup()\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a131a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flags Found on Level 4:\n",
      "flag-61\n",
      "\n",
      "Total Flags Found: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Level4FlagHunter:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the Level 4 Flag Hunter\n",
    "        \"\"\"\n",
    "        # Setup Chrome options\n",
    "        chrome_options = Options()\n",
    "        \n",
    "        # Add options to prevent detection and improve stability\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        \n",
    "        # Setup the WebDriver\n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=chrome_options\n",
    "        )\n",
    "        \n",
    "        self.url = url\n",
    "        # Existing flags to exclude (up to level 3)\n",
    "        self.existing_flags = set(f'flag-{i}' for i in range(1, 61))\n",
    "    \n",
    "    def load_page(self):\n",
    "        \"\"\"\n",
    "        Load the target page and wait for it to stabilize\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Navigate to the page\n",
    "            self.driver.get(self.url)\n",
    "            \n",
    "            # Wait for page to load completely\n",
    "            WebDriverWait(self.driver, 30).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, 'body'))\n",
    "            )\n",
    "            \n",
    "            # Additional wait for potential dynamic content\n",
    "            time.sleep(2)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading page: {e}\")\n",
    "    \n",
    "    def extract_flag(self):\n",
    "        \"\"\"\n",
    "        Extract flag by triggering the specific condition\n",
    "        \n",
    "        Returns:\n",
    "            set: Unique flags found\n",
    "        \"\"\"\n",
    "        flags = set()\n",
    "        \n",
    "        try:\n",
    "            # Find input element\n",
    "            input_element = self.driver.find_element(By.TAG_NAME, 'input')\n",
    "            \n",
    "            # Trigger the specific condition\n",
    "            input_element.clear()\n",
    "            input_element.send_keys('!!flag-61!!')\n",
    "            \n",
    "            # Wait for potential dynamic changes\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Check if flag is revealed\n",
    "            page_source = self.driver.page_source\n",
    "            if 'flag-61' in page_source:\n",
    "                flags.add('flag-61')\n",
    "            \n",
    "            # Additional verification\n",
    "            flag_elements = self.driver.find_elements(By.XPATH, \"//*[contains(text(), 'flag-61')]\")\n",
    "            if flag_elements:\n",
    "                flags.add('flag-61')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Flag extraction error: {e}\")\n",
    "        \n",
    "        return flags\n",
    "    \n",
    "    def find_level4_flags(self):\n",
    "        \"\"\"\n",
    "        Find all unique flags on level 4 page\n",
    "        \n",
    "        Returns:\n",
    "            set: All unique flags found\n",
    "        \"\"\"\n",
    "        # Extract flags\n",
    "        found_flags = self.extract_flag()\n",
    "        \n",
    "        # Remove existing flags and validate\n",
    "        unique_flags = {\n",
    "            flag for flag in found_flags \n",
    "            if flag.startswith('flag-') and \n",
    "               flag[5:].isdigit() and \n",
    "               flag not in self.existing_flags\n",
    "        }\n",
    "        \n",
    "        return unique_flags\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"\n",
    "        Close the browser and clean up resources\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Level 4 flag hunter\n",
    "    \"\"\"\n",
    "    url = \"https://hertie-scraping-website.vercel.app/level4\"\n",
    "    \n",
    "    # Create FlagHunter instance\n",
    "    flag_hunter = Level4FlagHunter(url)\n",
    "    \n",
    "    try:\n",
    "        # Load the page\n",
    "        flag_hunter.load_page()\n",
    "        \n",
    "        # Find flags\n",
    "        found_flags = flag_hunter.find_level4_flags()\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nFlags Found on Level 4:\")\n",
    "        for flag in sorted(found_flags):\n",
    "            print(flag)\n",
    "        print(f\"\\nTotal Flags Found: {len(found_flags)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Always ensure browser is closed\n",
    "        flag_hunter.cleanup()\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
